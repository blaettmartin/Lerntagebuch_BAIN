## 10. Lektion - Linked Data
In dieser Lektion wurden noch einige allgemeine Lücken geschlossen. Es gab auch eine kurze Vorführung von ALMA, welches in der Schweiz sehr verbreitet ist. Danach hatten wir noch einmal OpenRefine angewendet, diesesmal mit dem Fokus auf die Metaatenanreicherung.

#### Fragen an Bing AI
Zum Start haben wir die künstliche Intelligenz (KI) etwas getestet. Es sollten Fragen aus dem Bereich Bibliotheks- und Archivinformatik gestellt werden und mit unserem erworbenen Wissen abgeglichen werden. "Kennt" sich die KI in diesem Bereich aus und sind die Antworten schlüssig?
Meine Gruppe hat unteranderem nach einem Vergleich von AtoM und ArchivesSpace gefragt:
![image](https://github.com/blaettmartin/Lerntagebuch_BAIN/assets/90840517/eb299a8d-4a0e-4df0-9f21-abbf438fe782)  
Dabei ist uns speziell aufgefallen, das hier als Quellen auch Lerntagebücher aus diesem Kurs angegeben werden. Es ist also jeweils auch zu beachten welche Quellen hier angegeben werden. Die Resultate haben aber dementsprechend unseren Erkentnissen im Modul BAIN entsprochen. Wir haben auch bemerkt, dass bei diesem Vergleich vor allem die Vor- und Nachteile beider AIS genannt werden. Eine spezfisiche Empfehlung zu einem AIS wird nicht genannt und ist dadurch auch als eher objektiv zu sehen. 

Da ich Bing AI/ Bing Chat hier zum ersten Mal verwendet habe und davor nur ChatGPT direkt verwendet hatte, hier noch einige Punkte die mir dabei noch aufgefallen sind. Es handelt sich bei Bing Chat um einen KI Chatbot von Microsoft. Hier gibt es drei unterschiedliche Modi (kreativ, ausgewogen, genau), welche unterschiedliche Ergebnisse bieten kann und den Fokus dort verschieden setzt. Die Quellenangabe ist je nach Modus auch unterschiedlich.


#### Updates Aktuelle Datenmodelle
##### BIBFRAME
BIBFRAME wurde explizit als Nachfolger für MARC21 entwickelt und folgt den Linked Data Pradigmen. Es besteht aus dem _BIBFRAME Model_ und dem _BIBFRAME Vocabulary_. Im _Datenmodell_ werden die Entitäten (Agend, Subject & Event, etc.) defniert und zwischen Work, Instance und Item unterschieden. Das _Vokabular_ definiert hier die Eigenschaften zur Beschreibung der Entitäten des Datenmodells und das gesamte Konzept. Dieses übernimmt zum Teil die Konzepte von RDA.

Spannend ist es die [Gegenüberstellung](https://id.loc.gov/tools/bibframe/comparebf-lccn/2018958785.xml) von BIBFRAME und MARCXML zu betrachten. 
##### Records in Context (RiC)
Dies basiert auch auf den Linked-Data-Prinzipien. Es sollen dadurch neue und mehrfache Beziehungen möglich sein zwischen Entitäten, dies ist in ISAD(G) nicht so möglich. Es gibt eine VSA Projektgruppe, welche sich spezifisch mit RiC in der Schweiz befasst hatte. Seit April 2022 ist die [AG Normen und Standards](https://vsa-aas.ch/ressourcen/normen-und-standards/records-in-contexts/) zuständig.  

Es ist noch nicht ganz klar wie die Unterstützung von RiC durch Scopearchive möglich sein wird. Es wird also spannend sein, wie dieser neue Standard sich in der Archivwelt verbreiten wird.

#### Metadaten anreichern mit OpenRefine und Wikidata
Zum Abschluss war wurde noch einmal OpenRefine angewendet. Dies schliesst an die [3. Lektion](https://blaettmartin.github.io/Lerntagebuch_BAIN/Inhalte/3.Lektion.html) an. Heute wird hier nun die Reconciliation genauer betrachtet. Metadaten können so angereichert sein, Voraussetzungen dafür sind einheitliche Daten. Die Library Carpentry hat hierzu einen [Beitrag mit häufigen Fehlern](https://librarycarpentry.org/lc-spreadsheets/02-common-mistakes.html#metadata).  

Die [Reconciliation](https://openrefine.org/docs/manual/reconciling#sources) hatten wir in drei Schritten ausgeführt.

1. Schritt war der Import von Beispieldaten. Wir hatten eine Liste von Schriftsteller*innen im CSV-Format importiert.
![image](https://github.com/blaettmartin/Lerntagebuch_BAIN/assets/90840517/14318a1b-8448-4bba-b74a-6a902c8a4582)

2. Schritt war der Abgleich der Beispieldaten mit externen Datenquellen.
   ![image](https://github.com/blaettmartin/Lerntagebuch_BAIN/assets/90840517/bfdc05a7-32b9-4ede-9985-907c0b0ddc09)

   _Hier muss aufgepasst werden, dass der richtige Typ von Daten ausgewählt wird._
   ![image](https://github.com/blaettmartin/Lerntagebuch_BAIN/assets/90840517/bd7fa936-8dcc-4361-8c19-0d816266ca42)

3. Schritt war das übernehmen, der Daten aus Wikidaten für die abgeglichenen Einträge.
   ![image](https://github.com/blaettmartin/Lerntagebuch_BAIN/assets/90840517/f2a77dcd-0177-45d6-bf4b-d902bf0de636)
   _Bei einer einzelnen Zuordnung - also "Match this Cell" ist dies nicht automatisiert möglich. Damit es automatisiert geht, müsste man "Match all identical Cells" wählen._

Ein höherer Konfidenzwert deutet darauf hin, dass es sich um die passenden Daten handelt. Dieser Wert kann sich erhöhen wenn mehrere Angaben verglichen werden, zb. wenn noch das Geburtsjahr bei den Namen hinzugefügt werden. So können bei einem Automatch möglichst viele richtig zugeordnet werden.
   

